{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46ca0e-80ac-42b1-b2ce-7678c955099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports & Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84832c4-d04c-44bf-9e5a-b150a9a753cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "# Notebook is inside Notebooks/, so project root is one level up\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name.lower() == \"notebooks\" else Path.cwd()\n",
    "\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "MODEL_TABLE_PATH = DATA_PROCESSED / \"eurusd_h1_model_table_rv24h.parquet\"\n",
    "SPLIT_REPORT_PATH = DATA_PROCESSED / \"eurusd_h1_walkforward_splits_rv24h.csv\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"MODEL_TABLE_PATH exists:\", MODEL_TABLE_PATH.exists())\n",
    "print(\"SPLIT_REPORT_PATH exists:\", SPLIT_REPORT_PATH.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3449a39-06cb-4dba-910a-7c9f71bb54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modeling table\n",
    "model_df = pd.read_parquet(MODEL_TABLE_PATH).sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "print(\"Shape:\", model_df.shape)\n",
    "print(\"Date range:\", model_df[\"timestamp\"].min(), \"→\", model_df[\"timestamp\"].max())\n",
    "model_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869e9f8-a231-4bdc-9db6-8af1e8819fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Walk-forward splits\n",
    "\n",
    "We will rebuild splits from the timestamps to ensure we have real index arrays for training/testing.\n",
    "\n",
    "(We also keep the CSV split report from Notebook 02 for reference.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a8113-bad1-4690-b7fd-ef81f9927d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#walk-forward split function — tz safe\n",
    "def make_walk_forward_splits(timestamps, train_months=18, test_months=3, step_months=3):\n",
    "    ts = pd.to_datetime(timestamps)\n",
    "\n",
    "    # Ensure tz-aware in UTC (your timestamps are datetime64[ns, UTC])\n",
    "    if getattr(ts.dt, \"tz\", None) is None:\n",
    "        ts = ts.dt.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        ts = ts.dt.tz_convert(\"UTC\")\n",
    "\n",
    "    # Boundaries (month aligned)\n",
    "    start = ts.min().to_period(\"M\").to_timestamp().tz_localize(\"UTC\")\n",
    "    end   = ts.max().to_period(\"M\").to_timestamp().tz_localize(\"UTC\")\n",
    "\n",
    "    splits = []\n",
    "    current_train_start = start\n",
    "\n",
    "    while True:\n",
    "        train_end = current_train_start + pd.DateOffset(months=train_months)\n",
    "        test_end  = train_end + pd.DateOffset(months=test_months)\n",
    "\n",
    "        if test_end > end:\n",
    "            break\n",
    "\n",
    "        train_mask = (ts >= current_train_start) & (ts < train_end)\n",
    "        test_mask  = (ts >= train_end) & (ts < test_end)\n",
    "\n",
    "        train_idx = np.where(train_mask.to_numpy())[0]\n",
    "        test_idx  = np.where(test_mask.to_numpy())[0]\n",
    "\n",
    "        if len(train_idx) > 0 and len(test_idx) > 0:\n",
    "            splits.append((train_idx, test_idx))\n",
    "\n",
    "        current_train_start = current_train_start + pd.DateOffset(months=step_months)\n",
    "\n",
    "    return splits\n",
    "\n",
    "splits = make_walk_forward_splits(model_df[\"timestamp\"], train_months=18, test_months=3, step_months=3)\n",
    "print(\"Number of splits:\", len(splits))\n",
    "\n",
    "train_idx, test_idx = splits[0]\n",
    "print(\"First split:\")\n",
    "print(\" Train:\", model_df.loc[train_idx, \"timestamp\"].min(), \"→\", model_df.loc[train_idx, \"timestamp\"].max())\n",
    "print(\" Test: \", model_df.loc[test_idx, \"timestamp\"].min(), \"→\", model_df.loc[test_idx, \"timestamp\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa2851-2b33-441e-8359-785ad4e5a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target + Features\n",
    "TARGET = \"rv_24h\"\n",
    "FEATURES = [c for c in model_df.columns if c not in [\"timestamp\", TARGET]]\n",
    "\n",
    "X = model_df[FEATURES]\n",
    "y = model_df[TARGET]\n",
    "\n",
    "print(\"Num features:\", len(FEATURES))\n",
    "print(\"First 10 features:\", FEATURES[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5762ea3-0a92-4e14-a76e-b32352fe89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Helper \n",
    "def evaluate_on_splits(df, splits, model, features, target):\n",
    "    rows = []\n",
    "    preds_all = []  # optional, keep for later analysis\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(splits):\n",
    "        X_train = df.loc[train_idx, features]\n",
    "        y_train = df.loc[train_idx, target]\n",
    "\n",
    "        X_test = df.loc[test_idx, features]\n",
    "        y_test = df.loc[test_idx, target]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rows.append({\n",
    "            \"split\": i,\n",
    "            \"test_start\": df.loc[test_idx, \"timestamp\"].min(),\n",
    "            \"test_end\": df.loc[test_idx, \"timestamp\"].max(),\n",
    "            \"n_test\": len(test_idx),\n",
    "            \"mae\": mean_absolute_error(y_test, y_pred),\n",
    "            \"rmse\": mean_squared_error(y_test, y_pred, squared=False),\n",
    "        })\n",
    "\n",
    "        preds_all.append(pd.DataFrame({\n",
    "            \"timestamp\": df.loc[test_idx, \"timestamp\"].values,\n",
    "            \"y_true\": y_test.values,\n",
    "            \"y_pred\": y_pred,\n",
    "            \"split\": i\n",
    "        }))\n",
    "\n",
    "    results = pd.DataFrame(rows)\n",
    "    preds_all = pd.concat(preds_all, ignore_index=True)\n",
    "    return results, preds_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03770108-4b35-4947-9ebd-24a6728353c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge regression\n",
    "\n",
    "Ridge = linear regression with L2 regularization.\n",
    "We standardize features before fitting (important for regularization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f91cfe-9763-4e67-a6b3-516eb12b76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge model + results\n",
    "ridge_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "ridge_results, ridge_preds = evaluate_on_splits(model_df, splits, ridge_model, FEATURES, TARGET)\n",
    "\n",
    "ridge_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1736b00-17ea-4b7c-8e1a-61897b084474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge summary\n",
    "print(\"Ridge performance (across splits)\")\n",
    "print(\"MAE  mean:\", ridge_results[\"mae\"].mean())\n",
    "print(\"MAE   std:\", ridge_results[\"mae\"].std())\n",
    "print(\"RMSE mean:\", ridge_results[\"rmse\"].mean())\n",
    "print(\"RMSE  std:\", ridge_results[\"rmse\"].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb86960-408a-4146-9c03-2e272a085a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ElasticNet\n",
    "\n",
    "ElasticNet = linear regression with L1 + L2 regularization.\n",
    "It can shrink some coefficients to near zero (mild feature selection).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ee9fb-f504-4f5c-9e91-9213a6a3eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet model + results\n",
    "enet_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"enet\", ElasticNet(alpha=0.01, l1_ratio=0.3, max_iter=5000))\n",
    "])\n",
    "\n",
    "enet_results, enet_preds = evaluate_on_splits(model_df, splits, enet_model, FEATURES, TARGET)\n",
    "\n",
    "enet_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5c9e1-e2a8-4825-b4b7-09d68cf08a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet summary\n",
    "print(\"ElasticNet performance (across splits)\")\n",
    "print(\"MAE  mean:\", enet_results[\"mae\"].mean())\n",
    "print(\"MAE   std:\", enet_results[\"mae\"].std())\n",
    "print(\"RMSE mean:\", enet_results[\"rmse\"].mean())\n",
    "print(\"RMSE  std:\", enet_results[\"rmse\"].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9d014-6857-4830-8757-bc210bf042c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison Table\n",
    "comparison = pd.DataFrame({\n",
    "    \"model\": [\"Ridge\", \"ElasticNet\"],\n",
    "    \"mae_mean\": [ridge_results[\"mae\"].mean(), enet_results[\"mae\"].mean()],\n",
    "    \"rmse_mean\": [ridge_results[\"rmse\"].mean(), enet_results[\"rmse\"].mean()],\n",
    "    \"mae_std\": [ridge_results[\"mae\"].std(), enet_results[\"mae\"].std()],\n",
    "    \"rmse_std\": [ridge_results[\"rmse\"].std(), enet_results[\"rmse\"].std()],\n",
    "})\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6c473-cef0-4a92-965d-817fc372bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Ridge on ALL data for coefficient inspection\n",
    "ridge_full = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "ridge_full.fit(model_df[FEATURES], model_df[TARGET])\n",
    "\n",
    "coef = ridge_full.named_steps[\"ridge\"].coef_\n",
    "coef_df = pd.DataFrame({\"feature\": FEATURES, \"coef\": coef}).sort_values(\"coef\", ascending=False)\n",
    "\n",
    "print(\"Top positive coefficients:\")\n",
    "display(coef_df.head(15))\n",
    "\n",
    "print(\"Top negative coefficients:\")\n",
    "display(coef_df.tail(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304286c8-c7e0-48d5-9a68-bcfed195c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "out_ridge_results = DATA_PROCESSED / \"ridge_walkforward_results.csv\"\n",
    "out_enet_results  = DATA_PROCESSED / \"elasticnet_walkforward_results.csv\"\n",
    "out_ridge_preds   = DATA_PROCESSED / \"ridge_walkforward_predictions.parquet\"\n",
    "out_enet_preds    = DATA_PROCESSED / \"elasticnet_walkforward_predictions.parquet\"\n",
    "\n",
    "ridge_results.to_csv(out_ridge_results, index=False)\n",
    "enet_results.to_csv(out_enet_results, index=False)\n",
    "\n",
    "ridge_preds.to_parquet(out_ridge_preds, index=False)\n",
    "enet_preds.to_parquet(out_enet_preds, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", out_ridge_results)\n",
    "print(\" \", out_enet_results)\n",
    "print(\" \", out_ridge_preds)\n",
    "print(\" \", out_enet_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc223dda-5a5d-4bc3-94d4-0b794719a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next: add GARCH-style benchmark (EWMA) and LightGBM\n",
    "\n",
    "Now that we have clean linear baselines, we will add:\n",
    "- EWMA/GARCH-style volatility recursion benchmark\n",
    "- LightGBM gradient boosting model\n",
    "- A final comparison table across all models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c068c-7a3c-4164-8b36-07649243ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EWMA (GARCH-style) volatility benchmark\n",
    "\n",
    "EWMA variance recursion:\n",
    "    sigma2_t = λ * sigma2_{t-1} + (1-λ) * r_{t-1}^2\n",
    "\n",
    "This is a classic risk-model baseline (similar spirit to IGARCH/GARCH persistence).\n",
    "\n",
    "We then forecast forward 24h realized volatility with:\n",
    "    pred_rv_24h(t) = sqrt(24 * sigma2_t)\n",
    "\n",
    "and evaluate it with the same walk-forward splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202efb9-694b-43a7-b135-16648fcf8a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EWMA benchmark (NO ret_1h needed) ---\n",
    "# We smooth the past 24h realized volatility (vol_24h) to produce a forecast for next 24h volatility.\n",
    "\n",
    "TARGET = \"rv_24h\"\n",
    "LAMBDA = 0.94  # smoothing factor (higher = more persistence)\n",
    "\n",
    "model_df = model_df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# EWMA smoothing:\n",
    "# ewma_vol_t = λ * ewma_vol_{t-1} + (1-λ) * vol_24h_t\n",
    "model_df[\"ewma_vol_24h_pred\"] = model_df[\"vol_24h\"].ewm(alpha=(1 - LAMBDA), adjust=False).mean()\n",
    "\n",
    "print(\"Created EWMA prediction column: ewma_vol_24h_pred\")\n",
    "model_df[[\"timestamp\", \"vol_24h\", TARGET, \"ewma_vol_24h_pred\"]].dropna().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3797b01-9baa-4114-b646-19475707a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate EWMA benchmark on walk-forward splits ---\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def eval_pred_column(df, splits, y_col, pred_col):\n",
    "    rows = []\n",
    "    for i, (train_idx, test_idx) in enumerate(splits):\n",
    "        y_true = df.loc[test_idx, y_col].to_numpy()\n",
    "        y_pred = df.loc[test_idx, pred_col].to_numpy()\n",
    "\n",
    "        # Safety: drop NaNs/infs\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        y_true = y_true[mask]\n",
    "        y_pred = y_pred[mask]\n",
    "\n",
    "        rows.append({\n",
    "            \"split\": i,\n",
    "            \"test_start\": df.loc[test_idx, \"timestamp\"].min(),\n",
    "            \"test_end\": df.loc[test_idx, \"timestamp\"].max(),\n",
    "            \"n_test\": int(mask.sum()),\n",
    "            \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "            \"rmse\": mean_squared_error(y_true, y_pred, squared=False),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "ewma_results = eval_pred_column(model_df, splits, TARGET, \"ewma_vol_24h_pred\")\n",
    "\n",
    "ewma_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8038a-a84c-4f1d-ac90-481a102928cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWMA summury metrics\n",
    "print(\"EWMA(vol_24h) performance (across splits)\")\n",
    "print(\"MAE  mean:\", ewma_results[\"mae\"].mean())\n",
    "print(\"MAE   std:\", ewma_results[\"mae\"].std())\n",
    "print(\"RMSE mean:\", ewma_results[\"rmse\"].mean())\n",
    "print(\"RMSE  std:\", ewma_results[\"rmse\"].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3f83e-4d5c-42c0-9153-e1d40fe8e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Compare Ridge vs EWMA and ElasticNet\n",
    "comparison_all = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": \"Ridge\",\n",
    "        \"mae_mean\": ridge_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": ridge_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": ridge_results[\"mae\"].std(),\n",
    "        \"rmse_std\": ridge_results[\"rmse\"].std(),\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"ElasticNet\",\n",
    "        \"mae_mean\": enet_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": enet_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": enet_results[\"mae\"].std(),\n",
    "        \"rmse_std\": enet_results[\"rmse\"].std(),\n",
    "    },\n",
    "    {\n",
    "        \"model\": f\"EWMA(vol_24h, λ={LAMBDA})\",\n",
    "        \"mae_mean\": ewma_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": ewma_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": ewma_results[\"mae\"].std(),\n",
    "        \"rmse_std\": ewma_results[\"rmse\"].std(),\n",
    "    },\n",
    "]).sort_values(\"mae_mean\")\n",
    "\n",
    "comparison_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec5b65-3e67-4876-92ce-5f025f26dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save EWMA results\n",
    "out_ewma_results = DATA_PROCESSED / f\"ewma_vol24h_lambda_{str(LAMBDA).replace('.','_')}_results.csv\"\n",
    "ewma_results.to_csv(out_ewma_results, index=False)\n",
    "print(\"Saved EWMA split results to:\", out_ewma_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799a1ac-0d76-4e88-a1e5-bdf11926d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LightGBM (Gradient Boosting)\n",
    "\n",
    "Goal:\n",
    "- Train a non-linear model to predict `rv_24h`\n",
    "- Evaluate strictly using the same walk-forward splits\n",
    "- Compare against Ridge and EWMA\n",
    "\n",
    "Why LightGBM:\n",
    "- learns non-linear relationships and interactions (regimes)\n",
    "- performs very well on tabular financial features\n",
    "- robust and fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf12c31-5f43-4d1a-9d09-56fc87dd12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/Import\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(\"LightGBM version:\", lgb.__version__)\n",
    "except ModuleNotFoundError:\n",
    "    !pip -q install lightgbm\n",
    "    import lightgbm as lgb\n",
    "    print(\"LightGBM installed. Version:\", lgb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7066c347-d5b2-4127-ac9e-f550955b9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features for LightGBM\n",
    "TARGET = \"rv_24h\"\n",
    "\n",
    "EXCLUDE = {\"timestamp\", TARGET, \"ewma_vol_24h_pred\"}  # add more if you created other helper columns\n",
    "LGBM_FEATURES = [c for c in model_df.columns if c not in EXCLUDE]\n",
    "\n",
    "print(\"Num LightGBM features:\", len(LGBM_FEATURES))\n",
    "print(\"First 15 features:\", LGBM_FEATURES[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48aed8-67e2-4d18-898f-20790be8d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##train + evaluate LightGBM with walk-forward splits\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def train_eval_lightgbm(df, splits, features, target):\n",
    "    rows = []\n",
    "    preds_all = []\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(splits):\n",
    "        X_train = df.loc[train_idx, features]\n",
    "        y_train = df.loc[train_idx, target]\n",
    "        X_test  = df.loc[test_idx, features]\n",
    "        y_test  = df.loc[test_idx, target]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dvalid = lgb.Dataset(X_test, label=y_test, reference=dtrain)\n",
    "\n",
    "        params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"l1\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 63,          # ↓ from 63            \n",
    "    \"min_data_in_leaf\": 300,   # ↑ from 300\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"lambda_l2\": 1.0,         # ↑ stronger regularization\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "\n",
    "        booster = lgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[dvalid],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "        )\n",
    "\n",
    "        y_pred = booster.predict(X_test, num_iteration=booster.best_iteration)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "        rows.append({\n",
    "            \"split\": i,\n",
    "            \"test_start\": df.loc[test_idx, \"timestamp\"].min(),\n",
    "            \"test_end\": df.loc[test_idx, \"timestamp\"].max(),\n",
    "            \"n_test\": len(test_idx),\n",
    "            \"best_iter\": booster.best_iteration,\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "        })\n",
    "\n",
    "        preds_all.append(pd.DataFrame({\n",
    "            \"timestamp\": df.loc[test_idx, \"timestamp\"].values,\n",
    "            \"y_true\": y_test.values,\n",
    "            \"y_pred\": y_pred,\n",
    "            \"split\": i,\n",
    "        }))\n",
    "\n",
    "    return pd.DataFrame(rows), pd.concat(preds_all, ignore_index=True)\n",
    "\n",
    "lgbm_results, lgbm_preds = train_eval_lightgbm(model_df, splits, LGBM_FEATURES, TARGET)\n",
    "\n",
    "lgbm_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f38fc52-9e8a-4474-8804-470f51d48907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM summary\n",
    "print(\"LightGBM performance (across splits)\")\n",
    "print(\"MAE  mean:\", lgbm_results[\"mae\"].mean())\n",
    "print(\"MAE   std:\", lgbm_results[\"mae\"].std())\n",
    "print(\"RMSE mean:\", lgbm_results[\"rmse\"].mean())\n",
    "print(\"RMSE  std:\", lgbm_results[\"rmse\"].std())\n",
    "print(\"Median best_iter:\", int(lgbm_results[\"best_iter\"].median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d887f99-4865-4b28-826c-be49a86e0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final comparison table: Ridge vs EWMA vs LightGBM\n",
    "final_comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": \"Ridge\",\n",
    "        \"mae_mean\": ridge_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": ridge_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": ridge_results[\"mae\"].std(),\n",
    "        \"rmse_std\": ridge_results[\"rmse\"].std(),\n",
    "    },\n",
    "    {\n",
    "        \"model\": f\"EWMA(vol_24h, λ={LAMBDA})\",\n",
    "        \"mae_mean\": ewma_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": ewma_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": ewma_results[\"mae\"].std(),\n",
    "        \"rmse_std\": ewma_results[\"rmse\"].std(),\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"LightGBM\",\n",
    "        \"mae_mean\": lgbm_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": lgbm_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": lgbm_results[\"mae\"].std(),\n",
    "        \"rmse_std\": lgbm_results[\"rmse\"].std(),\n",
    "    },\n",
    "]).sort_values(\"mae_mean\")\n",
    "\n",
    "final_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e388db1-bb6c-414b-a980-3b406d9b42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a final model on last split for feature importance\n",
    "last_train_idx, last_test_idx = splits[-1]\n",
    "\n",
    "X_train = model_df.loc[last_train_idx, LGBM_FEATURES]\n",
    "y_train = model_df.loc[last_train_idx, TARGET]\n",
    "\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"l1\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_data_in_leaf\": 300,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"lambda_l2\": 1.0,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "best_rounds = int(lgbm_results[\"best_iter\"].median())\n",
    "booster = lgb.train(params, dtrain, num_boost_round=best_rounds)\n",
    "\n",
    "imp = pd.DataFrame({\n",
    "    \"feature\": LGBM_FEATURES,\n",
    "    \"gain\": booster.feature_importance(importance_type=\"gain\"),\n",
    "    \"split\": booster.feature_importance(importance_type=\"split\"),\n",
    "}).sort_values(\"gain\", ascending=False)\n",
    "\n",
    "imp.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6286b4-4452-4958-b50c-1231eb2a1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results \n",
    "out_lgbm_results = DATA_PROCESSED / \"lightgbm_walkforward_results.csv\"\n",
    "out_lgbm_preds   = DATA_PROCESSED / \"lightgbm_walkforward_predictions.parquet\"\n",
    "\n",
    "lgbm_results.to_csv(out_lgbm_results, index=False)\n",
    "lgbm_preds.to_parquet(out_lgbm_preds, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", out_lgbm_results)\n",
    "print(\" \", out_lgbm_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49450f30-d820-49fc-93a2-3b75f12f01cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary bar chart (MAE & RMSE)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Create plots directory if it does not exist\n",
    "PLOTS_DIR = \"plots\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Build a summary table (use your existing results)\n",
    "summary = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": \"Ridge\",\n",
    "        \"mae_mean\": ridge_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": ridge_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": ridge_results[\"mae\"].std(),\n",
    "        \"rmse_std\": ridge_results[\"rmse\"].std(),\n",
    "    },\n",
    "    {\n",
    "        \"model\": f\"EWMA (λ={LAMBDA})\",\n",
    "        \"mae_mean\": ewma_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": ewma_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": ewma_results[\"mae\"].std(),\n",
    "        \"rmse_std\": ewma_results[\"rmse\"].std(),\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"LightGBM\",\n",
    "        \"mae_mean\": lgbm_results[\"mae\"].mean(),\n",
    "        \"rmse_mean\": lgbm_results[\"rmse\"].mean(),\n",
    "        \"mae_std\": lgbm_results[\"mae\"].std(),\n",
    "        \"rmse_std\": lgbm_results[\"rmse\"].std(),\n",
    "    },\n",
    "]).sort_values(\"mae_mean\")\n",
    "\n",
    "# --- Bar chart with error bars ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(summary))\n",
    "width = 0.38\n",
    "\n",
    "plt.bar(\n",
    "    x - width/2,\n",
    "    summary[\"mae_mean\"],\n",
    "    width,\n",
    "    yerr=summary[\"mae_std\"],\n",
    "    capsize=4,\n",
    "    label=\"MAE (mean ± std)\"\n",
    ")\n",
    "plt.bar(\n",
    "    x + width/2,\n",
    "    summary[\"rmse_mean\"],\n",
    "    width,\n",
    "    yerr=summary[\"rmse_std\"],\n",
    "    capsize=4,\n",
    "    label=\"RMSE (mean ± std)\"\n",
    ")\n",
    "\n",
    "plt.xticks(x, summary[\"model\"], rotation=0)\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"EURUSD 24h Volatility Forecasting — Model Comparison (Walk-forward CV)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- Save ---\n",
    "barplot_path = os.path.join(PLOTS_DIR, \"model_comparison_mae_rmse.png\")\n",
    "plt.savefig(barplot_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Bar plot saved to: {barplot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aeab8c-ae14-4d90-9bc4-3281a2d1b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create plots directory if it does not exist\n",
    "PLOTS_DIR = \"plots\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "SPLIT_TO_PLOT = 0\n",
    "\n",
    "true_df = ridge_preds[ridge_preds[\"split\"] == SPLIT_TO_PLOT][[\"timestamp\",\"y_true\"]].rename(\n",
    "    columns={\"y_true\":\"True RV_24h\"}\n",
    ")\n",
    "ridge_df = ridge_preds[ridge_preds[\"split\"] == SPLIT_TO_PLOT][[\"timestamp\",\"y_pred\"]].rename(\n",
    "    columns={\"y_pred\":\"Ridge\"}\n",
    ")\n",
    "lgbm_df  = lgbm_preds[lgbm_preds[\"split\"] == SPLIT_TO_PLOT][[\"timestamp\",\"y_pred\"]].rename(\n",
    "    columns={\"y_pred\":\"LightGBM\"}\n",
    ")\n",
    "ewma_df  = model_df[[\"timestamp\",\"ewma_vol_24h_pred\"]].rename(\n",
    "    columns={\"ewma_vol_24h_pred\":f\"EWMA (λ={LAMBDA})\"}\n",
    ")\n",
    "\n",
    "# Fix timezone mismatch BEFORE merging\n",
    "true_df[\"timestamp\"]  = pd.to_datetime(true_df[\"timestamp\"], utc=True)\n",
    "ridge_df[\"timestamp\"] = pd.to_datetime(ridge_df[\"timestamp\"], utc=True)\n",
    "lgbm_df[\"timestamp\"]  = pd.to_datetime(lgbm_df[\"timestamp\"], utc=True)\n",
    "ewma_df[\"timestamp\"]  = pd.to_datetime(ewma_df[\"timestamp\"], utc=True)\n",
    "\n",
    "plot_df = (\n",
    "    true_df\n",
    "    .merge(ridge_df, on=\"timestamp\", how=\"left\")\n",
    "    .merge(lgbm_df, on=\"timestamp\", how=\"left\")\n",
    "    .merge(ewma_df, on=\"timestamp\", how=\"left\")\n",
    "    .sort_values(\"timestamp\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(plot_df[\"timestamp\"], plot_df[\"True RV_24h\"], linewidth=2, label=\"True RV_24h\")\n",
    "plt.plot(plot_df[\"timestamp\"], plot_df[\"Ridge\"], linewidth=1.5, label=\"Ridge\")\n",
    "plt.plot(plot_df[\"timestamp\"], plot_df[\"LightGBM\"], linewidth=1.5, label=\"LightGBM\")\n",
    "plt.plot(\n",
    "    plot_df[\"timestamp\"],\n",
    "    plot_df[f\"EWMA (λ={LAMBDA})\"],\n",
    "    linewidth=1.5,\n",
    "    label=f\"EWMA (λ={LAMBDA})\"\n",
    ")\n",
    "\n",
    "plt.title(\"EURUSD — True vs Predicted 24h Realized Volatility (Out-of-Sample)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- Save ---\n",
    "tsplot_path = os.path.join(PLOTS_DIR, \"volatility_forecast_timeseries.png\")\n",
    "plt.savefig(tsplot_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Time-series plot saved to: {tsplot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a349c0-b213-4e55-b7c7-74f74d876cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
